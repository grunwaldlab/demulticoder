---
title: "16S Mothur SOP Validation"
output: 
  rmarkdown::html_vignette:
    fig_path: "man/figures"
vignette: >
  %\VignetteIndexEntry{16S Mothur SOP Validation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "./",
  out.width = "60%",
  out.height = "550px"
)
```

```{r overwrite_existing_or_ont, echo=FALSE}
overwrite_existing <- FALSE
```

# This vignette shows how demulticoder was used to analyze the mothur 16S SOP dataset featured in DADA2 tutorials

Input metadata and primerinfo_params files are in data folder  

The only required columns are the first with sample names, and the second with the primer name/barcode used. The subsequent columns are user-specific columns for downstream steps
*metadata.csv file*
```{r, echo=FALSE}
# First, create your data frame
data <- data.frame(
  sample_name = c("F3D0", "F3D1", "F3D141", "F3D142", "F3D143", "F3D144", "F3D145", 
                  "F3D146", "F3D147", "F3D148", "F3D149", "F3D150", "F3D2", "F3D3", 
                  "F3D5", "F3D6", "F3D7", "F3D8", "F3D9", "Mock"),
  primer_name = rep("r16S", 20),
  Day = c(0, 1, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 2, 3, 5, 6, 7, 8, 9, NA),
  When = c(rep("Early", 2), rep("Late", 10), rep("Early", 7), NA)
)

# Now use knitr::kable() to create the table
knitr::kable(data, row.names = FALSE)
```

I then included the necessary second file with the name of the barcode selected, primer sequences, and the optional DADA2 parameter options. I referenced the DADA2 [tutorial](https://benjjneb.github.io/dada2/tutorial.html) to select the proper parameter options.  

Note, primers were already trimmed from reads, but just to be certain, I included the Earth Microbiome primers described [here](https://earthmicrobiome.org/protocols-and-standards/16s/), and a few primer sequences were still found within a small number of reads. 
*primerinfo_params.csv*
```{r, echo=FALSE}
# Create the data frame
primer_info <- data.frame(
  primer_name = "r16S",
  forward = "GTGYCAGCMGCCGCGGTAA",
  reverse = "GGACTACNVGGGTWTCTAAT",
  already_trimmed = TRUE,
  minCutadaptlength = 50,
  multithread = TRUE,
  verbose = TRUE,
  maxN = 0,
  maxEE_forward = 2,
  maxEE_reverse = 2,
  truncLen_forward = 240,
  truncLen_reverse = 160,
  truncQ = 2,
  minLen = 20,
  maxLen = Inf,
  minQ = 0,
  trimLeft = 0,
  trimRight = 0,
  rm.lowcomplex = 0,
  minOverlap = 12,
  maxMismatch = 0,
  min_asv_length = 50
)

# Use knitr::kable() to create the table
knitr::kable(primer_info, row.names = TRUE)
```

```{r setup, include=FALSE}
#devtools::install_github("grunwaldlab/demulticoder", force=TRUE)
devtools::load_all("~/demulticoder")
library("demulticoder")
```

### Step 1  
Remove N's and create directory structure for downstream steps
```{r prepare_reads, fig.height=6, fig.width=6, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
outputs<-prepare_reads(
  data_directory = "~/benchmark_demulticoder/mothur_16S_sop/data", 
  output_directory = "~/benchmark_demulticoder/mothur_16S_sop/vignette_outputs",
  tempdir_path = "~/benchmark_demulticoder/mothur_16S_sop/vignette_outputs_temp",
  tempdir_id = "temp_files")
```

### Step 2  
Run Cutadapt to remove primers and then trim reads with DADA2 filterAndTrim function 
```{r Remove_primers_and_trim_reads, fig.height=6, fig.width=6, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
cut_trim(
  outputs,
  cutadapt_path="/opt/homebrew/bin/cutadapt")
```

```{r visualize_outputs_cut_trim, echo=FALSE}
if (!overwrite_existing) {
  cat("Primer Removal-a few primer sequences may still remain, and if so, any ASVs with primer sequences will be filtered at the end\n")
  file_path <- system.file("extdata", "figures", "posttrim_primer_plot_16S.pdf", package = "demulticoder")
  knitr::include_graphics(file_path)
}
```

### Step 3  
Core ASV inference step
```{r ASV_inference, fig.height=6, fig.width=6, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
make_asv_abund_matrix(
  outputs)
```

```{r visualize_outputs_asv_inf, fig.height=10, fig.width=10, echo=FALSE}
if (!overwrite_existing) {
  cat("Plots showing info on how well forward and reverse reads were merged \n")
  knitr::include_graphics("~/benchmark_demulticoder/mothur_16S_sop/vignette_outputs/read_merging_info_r16S.pdf")
}

if (!overwrite_existing) {
  cat("Plot showing ASV length distribution \n")
  knitr::include_graphics("~/benchmark_demulticoder/mothur_16S_sop/vignette_outputs/asv_seqlength_plot_r16S.pdf")
}
```

### Step 4  
Assign taxonomy step
```{r assign_taxonomy_step, fig.height=6, fig.width=6, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
assign_tax(
  outputs,
  asv_abund_matrix,
  db_16S="silva_nr99_v138.2_toSpecies_trainset.fa.gz",
  retrieve_files=FALSE)
```

```{r view_read_counts, fig.height=10, fig.width=10, echo=FALSE}
if (!overwrite_existing) {
  cat("Tables showing read counts throughout the demulticoder DADA2 workflow\n")
 track_path <- "~/benchmark_demulticoder/mothur_16S_sop/vignette_outputs/track_reads_r16S.csv"
   read_track_file<-read.csv(track_path)
   print(read_track_file)
}
```

### Step 5  
Convert asv matrix to taxmap and phyloseq objects with one function
```{r convert_matrix_to_other_formats, fig.height=6, fig.width=6}
objs<-convert_asv_matrix_to_objs(outputs)
```

### Step 6  
Evaluate accuracy using mock community, as shown in dada2 tutorial
```{r examine_accuracy, fig.height=6, fig.width=6}
track_reads_demulticoder<-read.csv("~/benchmark_demulticoder/mothur_16S_sop/vignette_outputs/track_reads_r16S.csv", row.names = 1)
summary(track_reads_demulticoder)

tax_matrix<-read.csv("~/benchmark_demulticoder/mothur_16S_sop/vignette_outputs/final_asv_abundance_matrix_r16S.csv")

unqs.mock <- tax_matrix[, c(2, which(colnames(tax_matrix) == "Mock_r16S"))]

unqs.mock <- unqs.mock[unqs.mock$Mock_r16S != 0,]

cat("DADA2 inferred", nrow(unqs.mock), "sample sequences present in the Mock community.\n")

mock.ref <- dada2::getSequences(file.path("~/benchmark_demulticoder/mothur_16S_sop/data", "HMP_MOCK.v35.fasta"))
match.ref <- sum(sapply(unqs.mock$sequence, function(x) any(grepl(x, mock.ref))))
cat("Of those,", sum(match.ref), "were exact matches to the expected reference sequences.\n")
```

When looking at mock community sample, we were able to extract 20 bacterial sequences with 0% mismatch, and this matched what was described previously. 

### Step 7  
Follow-up work using phyloseq to do side-by-side comparison with dada2 example and to examine alpha diversity results
```{r phyloseq_alpha_diversity_analysis, fig.height=6, fig.width=6, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
objs$phyloseq_r16S <- phyloseq::prune_samples(phyloseq::sample_names(objs$phyloseq_r16S) != "Mock_r16S", objs$phyloseq_r16S) # Remove mock sample
phyloseq::plot_richness(objs$phyloseq_r16S, x="Day", measures=c("Shannon", "Simpson"), color="When")
```

### Step 8  
Examine ordination plots as additional point of comparison with DADA2 tutorial
```{r phyloseq_beta_diversity_analysis, fig.height=8, fig.width=8, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
# Transform data to proportions as appropriate for Bray-Curtis distances
ps.prop <- phyloseq::transform_sample_counts(objs$phyloseq_r16S, function(otu) otu/sum(otu))
ord.nmds.bray <- phyloseq::ordinate(ps.prop, method="NMDS", distance="bray")
phyloseq::plot_ordination(ps.prop, ord.nmds.bray, color="When", title="Bray NMDS")
```

### Step 9  
Let's look at what the top 20 taxa are in the early vs. late samples  time points, as shown in the dada2 tutorial
```{r phyloseq_community_analysis, fig.height=8, fig.width=8, echo=TRUE, results='hide', message=FALSE, warning=FALSE}
top20 <- names(sort(phyloseq::taxa_sums(objs$phyloseq_r16S), decreasing=TRUE))[1:20]
ps.top20 <- phyloseq::transform_sample_counts(objs$phyloseq_r16S, function(OTU) OTU/sum(OTU))
ps.top20 <- phyloseq::prune_taxa(top20, ps.top20)
phyloseq::plot_bar(ps.top20, x="Day", fill="Family") + ggplot2::facet_wrap(~When, scales="free_x")
```