
---
title: "Multiplexed and pooled barcode examples"
output: 
  rmarkdown::html_vignette:
    fig_path: "man/figures"
vignette: >
  %\VignetteIndexEntry{Multiplexed and pooled barcode examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "./"
)
```

## Demonstration of how to use demulticoder on a dataset that has pooled amplicoins (RPS10 and ITS)
Load package
```{r setup, include=FALSE}
#TODO-at some point switch to loading github repo version
devtools::install_github("grunwaldlab/demulticoder", force=TRUE)
library("demulticoder"); packageVersion("demulticoder")
```

Input metadata and primerinfo_params files are in data folder. This is a large dataset, so an example of the first three samples in the file is shown below. 

First, we prepare the *metadata.csv* file
```{r data_input, echo=FALSE}
# # First, create your data frame
# data <- data.frame(
#   sample_name = c("S1", "S1", "S10", "S10", "S100", "S100"),
#   primer_name = rep("rps10", "its","rps10", "its","rps10", "its"),
#   plate = c(1,1,1,1,2,2),
#   well = c("A01", "A01", "B02", "B02","B02", "B02"), 
#   organism=c("Cry","Cry","Cry","Cry","Cin", "Cin"),
#   flooded=c("TRUE", "TRUE", "TRUE", "TRUE","TRUE", "TRUE"),
#   path_conc=c(100, 100, 1, 1, 1, 1), 
#   experiment=c(1, 1, 1, 1, 2, 2),
#   sample_type=c("Sample", "Sample","Sample", "Sample","Sample", "Sample"), 
#   is_ambiguous=c("FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALSE"))
# 
# # Now use knitr::kable() to create the table
# knitr::kable(data, row.names = FALSE)
```


```{r primer_info, echo=FALSE}
# # Create the data frame
# primer_info <- data.frame(
#   primer_name = c("rps10",its),
#   forward = c("CTTGGTCATTTAGAGGAAGTAA","GTTGGTTAGAGYARAAGACT"), 
#   reverse = c("GCTGCGTTCTTCATCGATGC", "ATRYYTAGAAAGAYTYGAACT"),
#   already_trimmed = c("FALSE","FALSE"), 
#   minCutadaptlength = c(0,0),
#   multithread = c(TRUE,TRUE), 
#   verbose = c(TRUE,TRUE), 
#   maxN = c(0,0), 
#   maxEE_forward = c(5,5),
#   maxEE_reverse = c(5,5),
#   truncLen_forward=c(0,0),
#   truncLen_reverse=c(0,0),
#   truncQ = c(5,5), 
#   minLen = c(150,50),
#   maxLen = c(Inf,Inf), 
#   minQ = c(0,0), 
#   trimLeft = c(0,0),
#   trimRight = c(0,0),
#   rm.lowcomplex = c(0,0), 
#   minOverlap = c(15,15), 
#   maxMismatch = c(2,2),
#   min_asv_length = c(50,50)
# )
# 
# # Use knitr::kable() to create the table
# knitr::kable(primer_info, row.names = FALSE)
```

### Step 1-Remove N's and create directory structure for downstream steps
```{r prepare_reads, fig.height=6, fig.width=6}
outputs <- prepare_reads(
  data_directory = "~/benchmark_demulticoder/demulticoder/data", 
  output_directory = "~/benchmark_demulticoder/demulticoder/vignette_outputs",
  tempdir_path = "~/benchmark_demulticoder/demulticoder/vignette_outputs",
  tempdir_id = "temp_files",
  overwrite_existing = TRUE)
```

### Step 2-Run Cutadapt to remove primers and then trim reads with DADA2 filterAndTrim function 
```{r Remove_primers_and_trim_reads, fig.height=6, fig.width=6}
cut_trim(
  outputs,
  cutadapt_path="/usr/bin/cutadapt",
  overwrite_existing = FALSE)
```

```{r Conditional_graphics_chunk1, echo=FALSE, fig.height=6, fig.width=6}
if (!overwrite_existing) {
  image_path <- "~/benchmark_demulticoder/demulticoder/vignette_outputs/posttrim_primer_plot.pdf"
  if (file.exists(image_path)) {
    cat("### Primer Removal-a few primer sequences may still remain, and if so, any ASVs with primer sequences will be filtered at the end\n")
    knitr::include_graphics(image_path)
  }
}
```

### Step 3-Core ASV inference step
```{r ASV_inference, fig.height=6, fig.width=6}
make_asv_abund_matrix(
  outputs,
  overwrite_existing = FALSE)
```

```{r Conditional_graphics_chunk2, echo=FALSE, fig.height=6, fig.width=6}
if (!overwrite_existing) {
  image_directory <- "~/benchmark_demulticoder/demulticoder/vignette_outputs"
  image_prefix <- "read_merging_info"
  image_files <- list.files(image_directory, pattern = paste0("^", image_prefix), full.names = TRUE)
  for (image_path in image_files) {
    if (file.exists(image_path)) {
      cat("### Plots showing info on how well forward and reverse reads were merged \n")
      knitr::include_graphics(image_path)
    }
  }
}

if (!overwrite_existing) {
  image_directory <- "~/benchmark_demulticoder/demulticoder/vignette_outputs"
  image_prefix <- "asv_seqlength_plot"
  image_files <- list.files(image_directory, pattern = paste0("^", image_prefix), full.names = TRUE)
  for (image_path in image_files) {
    if (file.exists(image_path)) {
      cat("### Plot showing distribution of ASV lengths \n")
      knitr::include_graphics(image_path)
    }
  }
}
```

### Step 4- Taxonomic assignment step using DADA2 assignTaxonomy function an associated algorithm  
```{r assign_taxonomy_step, fig.height=6, fig.width=6}
assign_tax(
  outputs,
  asv_abund_matrix,
  db_its = "sh_general_release_dynamic_18.07.2023.fasta",
  db_rps10 = "oomycetedb_v2.fasta",
  retrieve_files=TRUE,
  tryRC = TRUE,
  overwrite_existing = FALSE)
```

```{r, Conditional_graphics_chunk3, echo=FALSE, fig.height=6, fig.width=6}
if (!overwrite_existing) {
  track_reads_dir <- "~/benchmark_demulticoder/demulticoder/vignette_outputs"
  file_prefix <- "track_reads"
  track_files <- list.file(track_reads_dir, pattern = paste0("^", file_prefix), full.names = TRUE)
  for (track_path in track_files) {
    if (file.exists(track_path)) {
      cat("### Tables showing read counts throughout the demulticoder DADA2 workflow\n")
      read_track_file<-read.csv(track_path)
      print(read_track_file)
    }
  }
}
```

### Step 5-convert asv matrix to taxmap and phyloseq objects with one function
```{r convert_matrix_to_other_formats,fig.height=6, fig.width=6}
objs<-convert_asv_matrix_to_objs(outputs, save_outputs=TRUE, overwrite_existing = TRUE)
```

### Step 6-let's make some quick visuals (heat trees) to take a look at outputs of the analyses   

At this point the rps10 and ITS1 analyses are separate. Given the greater complexity of this dataset, more robust analyses are detailed in the associated package manuscript and the analyses code is also linked.  

First we make a heat tree for our ITS-barcoded samples 
```{r Heatree_demonstration_its, message=FALSE}
objs$taxmap_its %>%
  filter_taxa(! grepl(x = taxon_names, "_sp$"), reassign_obs = FALSE) %>%
  filter_taxa(! grepl(x = taxon_names, "incertae_sedis", ignore.case = TRUE), reassign_obs = FALSE) %>%
  filter_taxa(! grepl(x = taxon_names, "NA", ignore.case = TRUE), reassign_obs = FALSE) %>%
  metacoder::heat_tree(node_label = taxon_names,
                       node_size = n_obs,
                       node_color = n_obs,
                       node_color_axis_label = "ASV count",
                       node_size_axis_label = "Total Abundance of Taxa",
                       layout = "da", initial_layout = "re")
```

Now we make a heat tree for our rps10-barcoded samples
```{r Heatree_demonstration_rps10, message=FALSE}
objs$taxmap_rps10 %>%
  filter_taxa(! grepl(x = taxon_names, "_sp$"), reassign_obs = FALSE) %>%
  filter_taxa(! grepl(x = taxon_names, "incertae_sedis", ignore.case = TRUE), reassign_obs = FALSE) %>%
  filter_taxa(! grepl(x = taxon_names, "NA", ignore.case = TRUE), reassign_obs = FALSE) %>%
  metacoder::heat_tree(node_label = taxon_names,
                       node_size = n_obs,
                       node_color = n_obs,
                       node_color_axis_label = "ASV count",
                       node_size_axis_label = "Total Abundance of Taxa",
                       layout = "da", initial_layout = "re")
```

```{r}
sessioninfo::session_info()
```