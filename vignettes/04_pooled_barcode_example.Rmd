---
title: "Multiplexed and pooled barcode examples"
output: 
  rmarkdown::html_vignette:
    fig_path: "man/figures"
vignette: >
  %\VignetteIndexEntry{Multiplexed and pooled barcode examples}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Demonstration of how to use demulticoder on a dataset that has pooled amplicoins (RPS10 and ITS)
Load package
```{r setup, include=FALSE}
#TODO-at some point switch to loading github repo version
devtools::install_github("grunwaldlab/demulticoder", force=TRUE)
library("demulticoder"); packageVersion("demulticoder")
```

Input metadata and primerinfo_params files are in data folder. This is a large dataset, so an example of the first three samples in the file is shown below. 

First, we prepare the *metadata.csv* file
```{r data input, echo=FALSE}
# # First, create your data frame
# data <- data.frame(
#   sample_name = c("S1", "S1", "S10", "S10", "S100", "S100"),
#   primer_name = rep("rps10", "its","rps10", "its","rps10", "its"),
#   plate = c(1,1,1,1,2,2),
#   well = c("A01", "A01", "B02", "B02","B02", "B02"), 
#   organism=c("Cry","Cry","Cry","Cry","Cin", "Cin"),
#   flooded=c("TRUE", "TRUE", "TRUE", "TRUE","TRUE", "TRUE"),
#   path_conc=c(100, 100, 1, 1, 1, 1), 
#   experiment=c(1, 1, 1, 1, 2, 2),
#   sample_type=c("Sample", "Sample","Sample", "Sample","Sample", "Sample"), 
#   is_ambiguous=c("FALSE", "FALSE", "FALSE", "FALSE", "FALSE", "FALSE"))
# 
# # Now use knitr::kable() to create the table
# knitr::kable(data, row.names = FALSE)
```


```{r primer_info, echo=FALSE}
# # Create the data frame
# primer_info <- data.frame(
#   primer_name = c("rps10",its),
#   forward = c("CTTGGTCATTTAGAGGAAGTAA","GTTGGTTAGAGYARAAGACT"), 
#   reverse = c("GCTGCGTTCTTCATCGATGC", "ATRYYTAGAAAGAYTYGAACT"),
#   already_trimmed = c("FALSE","FALSE"), 
#   minCutadaptlength = c(0,0),
#   multithread = c(TRUE,TRUE), 
#   verbose = c(TRUE,TRUE), 
#   maxN = c(0,0), 
#   maxEE_forward = c(5,5),
#   maxEE_reverse = c(5,5),
#   truncLen_forward=c(0,0),
#   truncLen_reverse=c(0,0),
#   truncQ = c(5,5), 
#   minLen = c(150,50),
#   maxLen = c(Inf,Inf), 
#   minQ = c(0,0), 
#   trimLeft = c(0,0),
#   trimRight = c(0,0),
#   rm.lowcomplex = c(0,0), 
#   minOverlap = c(15,15), 
#   maxMismatch = c(2,2),
#   min_asv_length = c(50,50)
# )
# 
# # Use knitr::kable() to create the table
# knitr::kable(primer_info, row.names = FALSE)
```

### Step 1-Remove N's and create directory structure for downstream steps
```{r prepare reads}
outputs<-prepare_reads(
  data_directory = "~/demulticoder_benchmarking/demulticoder_combined_analysis_rhode/data", 
  output_directory = "~/demulticoder_benchmarking/demulticoder_combined_analysis_rhode/outputs_vignette",
  tempdir_path = "~/demulticoder_benchmarking/demulticoder_combined_analysis_rhode/temp_vignette",
  tempdir_id = "temp_files",
  overwrite_existing = TRUE)
```

### Step 2-Run Cutadapt to remove primers and then trim reads with DADA2 filterAndTrim function 
```{r Remove primers and trim reads}
cut_trim(
  outputs,
  cutadapt_path="/usr/bin/cutadapt",
  overwrite_existing = FALSE)
```

### Step 3-Core ASV inference step
```{r ASV inference}
make_asv_abund_matrix(
  outputs,
  overwrite_existing = FALSE)
```

```{r assign taxonomy step}
assign_tax(
  outputs,
  asv_abund_matrix,
  db_its = "sh_general_release_dynamic_18.07.2023.fasta",
  db_rps10 = "oomycetedb_v2.fasta",
  retrieve_files=TRUE,
  tryRC = TRUE,
  overwrite_existing=FALSE)
```

### Step 5-convert asv matrix to taxmap and phyloseq objects with one function
```{r convert matrix to other formats}
objs<-convert_asv_matrix_to_objs(outputs, save_outputs=TRUE, overwrite_existing = FALSE)
```

```{r}
sessioninfo::session_info()
```