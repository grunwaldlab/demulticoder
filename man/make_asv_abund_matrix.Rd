% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/MakeASVAbundMatrix.R
\name{make_asv_abund_matrix}
\alias{make_asv_abund_matrix}
\title{Make an amplified sequence variants abundance matrix with data processed through preceding steps}
\usage{
make_asv_abund_matrix(
  directory_path,
  multithread = FALSE,
  nbases = 1e+08,
  errorEstimationFunction = loessErrfun,
  randomize = FALSE,
  MAX_CONSIST = 10,
  OMEGA_C = 0,
  qualityType = "Auto",
  nominalQ = FALSE,
  obs = TRUE,
  err_out = TRUE,
  err_in = FALSE,
  pool = FALSE,
  selfConsist = FALSE,
  verbose = FALSE,
  minOverlap = 12,
  maxMismatch = 0,
  returnRejects = FALSE,
  justConcatenate = FALSE,
  trimOverhang = FALSE,
  orderBy = "abundance",
  method = "consensus",
  min_asv_length = 50
)
}
\arguments{
\item{directory_path}{Folder path of read files and metadata file}

\item{multithread}{(Optional). Default is FALSE.
If TRUE, multithreading is enabled and the number of available threads is automatically determined.   
If an integer is provided, the number of threads to use is set by passing the argument on to
\code{\link{setThreadOptions}}.}

\item{nbases}{(Optional). Default 1e8.
The minimum number of total bases to use for error rate learning. Samples are read into memory
until at least this number of total bases has been reached, or all provided samples have been
read in.}

\item{errorEstimationFunction}{(Optional). Function. Default \code{\link[dada2]{loessErrfun}}.

 \code{errorEstimationFunction} is computed on the matrix of observed transitions
 after each sample inference step in order to generate the new matrix of estimated error rates.}

\item{randomize}{(Optional). Default FALSE.
If FALSE, samples are read in the provided order until enough reads are obtained.
If TRUE, samples are picked at random from those provided.}

\item{MAX_CONSIST}{(Optional). Default 10.
The maximum number of times to step through the self-consistency loop. If convergence was not
reached in MAX_CONSIST steps, the estimated error rates in the last step are returned.}

\item{OMEGA_C}{(Optional). Default 0.
The threshold at which unique sequences inferred to contain errors are corrected in the final output,
 and used to estimate the error rates (see more at \code{\link[dada2]{setDadaOpt}}). For reasons of convergence,
 and because it is more conservative, it is recommended to set this value to 0, which means that all
 reads are counted and contribute to estimating the error rates.}

\item{qualityType}{(Optional). \code{character(1)}.
The quality encoding of the fastq file(s). "Auto" (the default) means to
attempt to auto-detect the encoding. This may fail for PacBio files with
uniformly high quality scores, in which case use "FastqQuality". This
parameter is passed on to \code{\link[ShortRead]{readFastq}}; see
information there for details.}

\item{nominalQ}{(Optional). Default FALSE.
If TRUE, plot the expected error rates (red line) if quality scores
exactly matched their nominal definition: Q = -10 log10(p_err).}

\item{obs}{(Optional). Default TRUE.
If TRUE, the observed error rates are plotted as points.}

\item{err_out}{(Optional). Default TRUE.
If TRUE, plot the output error rates (solid line).}

\item{err_in}{(Optional). Default FALSE.
If TRUE, plot the input error rates (dashed line).}

\item{pool}{(Optional). \code{logical(1)}. Default is FALSE.

 If pool = TRUE, the algorithm will pool together all samples prior to sample inference.
 If pool = FALSE, sample inference is performed on each sample individually.
 If pool = "pseudo", the algorithm will perform pseudo-pooling between individually processed samples.
 
 This argument has no effect if only 1 sample is provided, and \code{pool} does not affect
  error rates, which are always estimated from pooled observations across samples.}

\item{selfConsist}{(Optional). \code{logical(1)}. Default FALSE.

 If selfConsist = TRUE, the algorithm will alternate between sample inference and error rate estimation 
   until convergence. Error rate estimation is performed by \code{errorEstimationFunction}.
   
 If selfConsist=FALSE the algorithm performs one round of sample inference based on the provided \code{err} matrix.}

\item{verbose}{(Optional). Default TRUE 
 Print verbose text output. More fine-grained control is available by providing an integer argument.
\itemize{ 
 \item{0: Silence. No text output (same as FALSE).}
 \item{1: Basic text output (same as TRUE). }
 \item{2: Detailed text output, mostly intended for debugging. }
}}

\item{minOverlap}{(Optional). Default 12.
The minimum length of the overlap required for merging the forward and reverse reads.}

\item{maxMismatch}{(Optional). Default 0. 
The maximum mismatches allowed in the overlap region.}

\item{returnRejects}{(Optional). Default FALSE.
If TRUE, the pairs that that were rejected based on mismatches in the overlap
region are retained in the return \code{data.frame}.}

\item{justConcatenate}{(Optional). Default FALSE.
If TRUE, the forward and reverse-complemented reverse read are concatenated rather than merged,
  with a NNNNNNNNNN (10 Ns) spacer inserted between them.}

\item{trimOverhang}{(Optional). Default FALSE.
If TRUE, "overhangs" in the alignment between the forwards and reverse read are trimmed off.
"Overhangs" are when the reverse read extends past the start of the forward read, and vice-versa,
as can happen when reads are longer than the amplicon and read into the other-direction primer region.}

\item{rawSeqTab_fileName}{A filename as which the raw sequence table will be saved}

\item{abundMatrix_fileName}{A filename as which the abundance matrix will be saved}
}
\value{
The asv abundance matrix asv_abund_matrix
}
\description{
Make an amplified sequence variants abundance matrix with data processed through preceding steps
}
\examples{
directory_path<-"~/rps10package/raw_data/rps10_ITS"
primer_path <-file.path(directory_path, "primer_info.csv")
metadata_path <-file.path(directory_path,"metadata.csv")
cutadapt_path<-"/opt/homebrew/bin/cutadapt"
data_tables <-
prepare_reads(
directory_path,
primer_path,
metadata_path,
maxN = 0,
)
cut_trim(
directory_path,
cutadapt_path,
verbose = TRUE,
maxEE = 2,
truncQ = 5,
minLen = 200,
maxLen = 297,
minCutadaptlength = 50
)
asv_abund_matrix <-
make_asv_abund_matrix(
directory_path,
minOverlap = 15,
maxMismatch = 2,
verbose = TRUE,
)




}
