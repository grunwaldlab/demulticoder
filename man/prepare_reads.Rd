% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PrepareReads_CountPrimers.R
\name{prepare_reads}
\alias{prepare_reads}
\title{Main command prepare reads for primer trimming}
\usage{
prepare_reads(
  directory_path,
  primer_path,
  metadata_path,
  maxN = 0,
  multithread = FALSE
)
}
\arguments{
\item{directory_path}{A path to the intermediate folder and directory}

\item{primer_path}{The primer data tibble created
in orient_primers function}

\item{metadata_path}{A path to a metadata containing
the concatenated metadata and primer data}

\item{maxN}{(Optional). Default 0.
After truncation, sequences with more than \code{maxN} Ns will be discarded. 
Note that \code{\link[dada2]{dada}} does not allow Ns.}

\item{multithread}{(Optional). Default is FALSE.
 If TRUE, input files are filtered in parallel via \code{\link[parallel]{mclapply}}.
 If an integer is provided, it is passed to the \code{mc.cores} argument of \code{\link[parallel]{mclapply}}.
 Note that the parallelization here is by forking, and each process is loading another fastq file into
 memory. This option is ignored in Windows, as Windows does not support forking, with \code{mc.cores} set to 1.
If memory is an issue, execute in a clean environment and reduce the chunk size \code{n} and/or
 the number of threads.}
}
\value{
A list containing data modified by cutadapt,
primer data, FASTQ data, and concatenated metadata and primer data
}
\description{
Main command prepare reads for primer trimming
}
\examples{
directory_path<-"~/rps10package/raw_data/rps10_ITS"
primer_path <-file.path(directory_path, "primer_info.csv")
metadata_path <-file.path(directory_path,"metadata.csv")
cutadapt_path<-"/opt/homebrew/bin/cutadapt"
data_tables <-
prepare_reads(
directory_path,
primer_path,
metadata_path,
maxN = 0,
)

}
